{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Output\n",
    "\n",
    "This notebook goes over how to output fitted encoders, standardizers, and models.\n",
    "\n",
    "[Pickle](https://docs.python.org/3/library/pickle.html) and [JobLib](https://joblib.readthedocs.io/en/latest/index.html) were utilized to output fitted encoders, standardizers, and fitted models.\n",
    "\n",
    "**Note**: Pickle *could* be used to output fitted models. However, Pickle can output very large files for more complicated models. Therefore, while not necessarily not required for this project, in the name of good practice, was used to output the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and Manipulate Data\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "#Pre-processing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Export Fitted Data\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "#Turn off warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import\n",
    "\n",
    "Import and drop missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../data/crime_census_weather_tod.db')        \n",
    "df = pd.read_sql_query(\"select * from all_crimes\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Block Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "bg_fit = le.fit(df['BLOCK_GROUP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bg_cat'] = bg_fit.transform(df['BLOCK_GROUP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Features\n",
    "\n",
    "The only features that are standardized in this notebook are those features used in the final model. For a review of feature selection and a standardization of all features, see [Model_Feature_Standardization](https://github.com/georgetown-analytics/DC-Criminalistics/blob/master/notebooks/Model_Feature_Standardization.ipynb), [Model_Feature_Selection_Modeling](https://github.com/georgetown-analytics/DC-Criminalistics/blob/master/notebooks/Model_Feature_Selection_Modeling.ipynb) notebooks.\n",
    "\n",
    "\n",
    "**Features**: Census block group, day of the month, day of the week, time of day, temperature, and UV index.  \n",
    "**Target**: Standardized and classified crime rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    'bg_cat', 'day', 'weekday', 'tod_num', 'temperature', 'uv_index',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler_fit = scaler.fit(df[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(scaler_fit.transform(df[feature_cols]),\n",
    "                        columns=feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['crime_rate_cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "**Model**: Bagging Classifier with Decision Tree estimator, which is the default estimator for this classifier.\n",
    "\n",
    "For a more detailed exposition of other models and techniques used to run and store multiple models in working memory, see [Model_Feature_Selection_Modeling](https://github.com/georgetown-analytics/DC-Criminalistics/blob/master/notebooks/Model_Feature_Selection_Modeling.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingClassifier(base_estimator=DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_fit = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Data\n",
    "\n",
    "We have three fits we need to export:\n",
    "1. Encodeded block group\n",
    "2. Standardized features\n",
    "3. Bagging classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block Group Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bg_fit, open('../model/block-group-encoding-fit.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler_fit, open('../model/feature-standardization-fit.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Classifier with Decision Tree Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(bc_fit, '../model/bagging-classifier-fit.sav')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
